# Retrieval-Augmented-Generation-with-Llama-2-and-LangChain
Retrieval-Augmented Generation (RAG) is a technique that combines a retriever and a generative language model to deliver accurate response. It involves retrieving relevant information from a large corpus and then generating contextually appropriate responses to queries. Here we use the quantized version of the Llama 2 13B LLM with LangChain to perform generative QA with RAG. The notebook file has been tested in Google Colab with T4 GPU. 

![image](https://github.com/muntasirhsn/Retrieval-Augmented-Generation-with-Llama-2/assets/29087240/0be4ab98-43f3-47f2-8520-5833630671fc)

Figure: A schematic representation of RAG with a retriever and an LLM
